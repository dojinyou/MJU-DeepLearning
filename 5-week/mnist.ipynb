{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "dEqCsbkWjzBi"
      },
      "outputs": [],
      "source": [
        "# colab 연결용\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor,Lambda\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "U0NPjAoSkEuL"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_norm_transform = transforms.Compose([\n",
        "    ToTensor(),\n",
        "    transforms.Lambda(lambda x:x*256)\n",
        "])"
      ],
      "metadata": {
        "id": "8zdnsR0Il153"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=not_norm_transform,\n",
        "    # transform=ToTensor(),\n",
        "    # target_transform=Lambda(\n",
        "    #     lambda y: torch.zeros(10,dtype=torch.float).scatter_(0, torch.tensor(y),value=1)\n",
        "    # )\n",
        ")"
      ],
      "metadata": {
        "id": "4rLbKZ9zlL13"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "cn6K5YyM_i4b"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_data[0][0])\n",
        "print(training_data[0][0].shape)\n",
        "print(type(training_data[0][0]))\n",
        "print(training_data[0][1])"
      ],
      "metadata": {
        "id": "NOvhow_BAoZ0",
        "outputId": "129c9f84-9251-44da-abdc-4a09870645dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "<class 'torch.Tensor'>\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "9jmYBfP8F4z7"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "EZ-NB4zIB2-m"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feedforward Model\n",
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    outputs = self.linear_relu_stack(x)\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "xj4qTXsBlOGt"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 0.001\n",
        "epochs = 20\n",
        "model = MLP().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "SLssKZyBmdRX"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for batch_idx, (X_train, y_train) in enumerate(train_dataloader):\n",
        "    # Train\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    X_train = X_train.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "    pred = model(X_train)\n",
        "    loss = criterion(pred, y_train)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if batch_idx % 100 == 0:\n",
        "      loss, current = loss.item(), batch_idx * len(X_train)\n",
        "      print(f\"loss : {loss::>7f} [{current:>5d}/{len(train_dataloader.dataset):>5d}]\")\n",
        "      \n",
        "  test_loss, correct = 0,0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for X_test,y_test in test_dataloader:\n",
        "      X_test = X_test.to(device)\n",
        "      y_test = y_test.to(device)\n",
        "      pred = model(X_test)\n",
        "      test_loss += criterion(pred,y_test).item()\n",
        "      correct += (pred.argmax(1) == y_test).type(torch.float).sum().item()\n",
        "    test_loss /= len(test_dataloader)\n",
        "    correct /= len(test_dataloader.dataset)\n",
        "    print(f\"Test Error:\\n Accurancy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8}\\n\")\n"
      ],
      "metadata": {
        "id": "xT4zn8UMCh3y",
        "outputId": "ccf1623a-d736-4730-cc2e-5b6cedf6a5b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 2.478134 [    0/60000]\n",
            "loss : 1.436693 [ 6400/60000]\n",
            "loss : 1.206418 [12800/60000]\n",
            "loss : 1.096959 [19200/60000]\n",
            "loss : 0.941077 [25600/60000]\n",
            "loss : 0.828868 [32000/60000]\n",
            "loss : 0.769698 [38400/60000]\n",
            "loss : 0.583169 [44800/60000]\n",
            "loss : 0.741031 [51200/60000]\n",
            "loss : 0.532392 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 79.5%, Avg loss: 0.6480090702965315\n",
            "\n",
            "loss : 0.620497 [    0/60000]\n",
            "loss : 0.637454 [ 6400/60000]\n",
            "loss : 0.617838 [12800/60000]\n",
            "loss : 0.706904 [19200/60000]\n",
            "loss : 0.609578 [25600/60000]\n",
            "loss : 0.643370 [32000/60000]\n",
            "loss : 0.562410 [38400/60000]\n",
            "loss : 0.563577 [44800/60000]\n",
            "loss : 0.412550 [51200/60000]\n",
            "loss : 0.755154 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 82.7%, Avg loss: 0.5238133467463796\n",
            "\n",
            "loss : 0.463059 [    0/60000]\n",
            "loss : 0.509420 [ 6400/60000]\n",
            "loss : 0.526924 [12800/60000]\n",
            "loss : 0.690777 [19200/60000]\n",
            "loss : 0.560256 [25600/60000]\n",
            "loss : 0.579279 [32000/60000]\n",
            "loss : 0.436068 [38400/60000]\n",
            "loss : 0.397369 [44800/60000]\n",
            "loss : 0.509776 [51200/60000]\n",
            "loss : 0.459988 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 84.3%, Avg loss: 0.46736688660914455\n",
            "\n",
            "loss : 0.487300 [    0/60000]\n",
            "loss : 0.565186 [ 6400/60000]\n",
            "loss : 0.543105 [12800/60000]\n",
            "loss : 0.342573 [19200/60000]\n",
            "loss : 0.569285 [25600/60000]\n",
            "loss : 0.439692 [32000/60000]\n",
            "loss : 0.644830 [38400/60000]\n",
            "loss : 0.468383 [44800/60000]\n",
            "loss : 0.446154 [51200/60000]\n",
            "loss : 0.588265 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 85.1%, Avg loss: 0.43339371274529237\n",
            "\n",
            "loss : 0.397273 [    0/60000]\n",
            "loss : 0.371223 [ 6400/60000]\n",
            "loss : 0.478578 [12800/60000]\n",
            "loss : 0.350362 [19200/60000]\n",
            "loss : 0.387277 [25600/60000]\n",
            "loss : 0.497210 [32000/60000]\n",
            "loss : 0.293745 [38400/60000]\n",
            "loss : 0.346895 [44800/60000]\n",
            "loss : 0.507902 [51200/60000]\n",
            "loss : 0.358761 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 85.9%, Avg loss: 0.40920931810953975\n",
            "\n",
            "loss : 0.481406 [    0/60000]\n",
            "loss : 0.489417 [ 6400/60000]\n",
            "loss : 0.567491 [12800/60000]\n",
            "loss : 0.526502 [19200/60000]\n",
            "loss : 0.416700 [25600/60000]\n",
            "loss : 0.584725 [32000/60000]\n",
            "loss : 0.485087 [38400/60000]\n",
            "loss : 0.412026 [44800/60000]\n",
            "loss : 0.405220 [51200/60000]\n",
            "loss : 0.359353 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 86.5%, Avg loss: 0.3912640953146573\n",
            "\n",
            "loss : 0.366449 [    0/60000]\n",
            "loss : 0.317472 [ 6400/60000]\n",
            "loss : 0.356919 [12800/60000]\n",
            "loss : 0.342964 [19200/60000]\n",
            "loss : 0.407917 [25600/60000]\n",
            "loss : 0.413281 [32000/60000]\n",
            "loss : 0.411907 [38400/60000]\n",
            "loss : 0.332050 [44800/60000]\n",
            "loss : 0.332648 [51200/60000]\n",
            "loss : 0.359659 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 87.0%, Avg loss: 0.37691679547654033\n",
            "\n",
            "loss : 0.427707 [    0/60000]\n",
            "loss : 0.281928 [ 6400/60000]\n",
            "loss : 0.358948 [12800/60000]\n",
            "loss : 0.351529 [19200/60000]\n",
            "loss : 0.306210 [25600/60000]\n",
            "loss : 0.332006 [32000/60000]\n",
            "loss : 0.420712 [38400/60000]\n",
            "loss : 0.383202 [44800/60000]\n",
            "loss : 0.396049 [51200/60000]\n",
            "loss : 0.330626 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 87.4%, Avg loss: 0.3665313075092047\n",
            "\n",
            "loss : 0.433977 [    0/60000]\n",
            "loss : 0.431967 [ 6400/60000]\n",
            "loss : 0.279054 [12800/60000]\n",
            "loss : 0.325883 [19200/60000]\n",
            "loss : 0.362512 [25600/60000]\n",
            "loss : 0.425660 [32000/60000]\n",
            "loss : 0.457425 [38400/60000]\n",
            "loss : 0.357344 [44800/60000]\n",
            "loss : 0.322344 [51200/60000]\n",
            "loss : 0.252779 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 87.7%, Avg loss: 0.3533872902742835\n",
            "\n",
            "loss : 0.464529 [    0/60000]\n",
            "loss : 0.392985 [ 6400/60000]\n",
            "loss : 0.410602 [12800/60000]\n",
            "loss : 0.319403 [19200/60000]\n",
            "loss : 0.367915 [25600/60000]\n",
            "loss : 0.328911 [32000/60000]\n",
            "loss : 0.314279 [38400/60000]\n",
            "loss : 0.463049 [44800/60000]\n",
            "loss : 0.236133 [51200/60000]\n",
            "loss : 0.341131 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 88.0%, Avg loss: 0.3439980085565846\n",
            "\n",
            "loss : 0.215759 [    0/60000]\n",
            "loss : 0.332697 [ 6400/60000]\n",
            "loss : 0.380606 [12800/60000]\n",
            "loss : 0.269064 [19200/60000]\n",
            "loss : 0.521645 [25600/60000]\n",
            "loss : 0.359449 [32000/60000]\n",
            "loss : 0.428208 [38400/60000]\n",
            "loss : 0.391651 [44800/60000]\n",
            "loss : 0.285340 [51200/60000]\n",
            "loss : 0.306160 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 88.3%, Avg loss: 0.3364507927855195\n",
            "\n",
            "loss : 0.279715 [    0/60000]\n",
            "loss : 0.405339 [ 6400/60000]\n",
            "loss : 0.364758 [12800/60000]\n",
            "loss : 0.247566 [19200/60000]\n",
            "loss : 0.340643 [25600/60000]\n",
            "loss : 0.214971 [32000/60000]\n",
            "loss : 0.274756 [38400/60000]\n",
            "loss : 0.528513 [44800/60000]\n",
            "loss : 0.360590 [51200/60000]\n",
            "loss : 0.357650 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 88.4%, Avg loss: 0.33094410384610007\n",
            "\n",
            "loss : 0.164669 [    0/60000]\n",
            "loss : 0.405184 [ 6400/60000]\n",
            "loss : 0.452547 [12800/60000]\n",
            "loss : 0.382988 [19200/60000]\n",
            "loss : 0.409539 [25600/60000]\n",
            "loss : 0.320611 [32000/60000]\n",
            "loss : 0.212431 [38400/60000]\n",
            "loss : 0.292559 [44800/60000]\n",
            "loss : 0.322618 [51200/60000]\n",
            "loss : 0.321580 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 88.8%, Avg loss: 0.3196852535072929\n",
            "\n",
            "loss : 0.323214 [    0/60000]\n",
            "loss : 0.264677 [ 6400/60000]\n",
            "loss : 0.212786 [12800/60000]\n",
            "loss : 0.323977 [19200/60000]\n",
            "loss : 0.534645 [25600/60000]\n",
            "loss : 0.434639 [32000/60000]\n",
            "loss : 0.137738 [38400/60000]\n",
            "loss : 0.372714 [44800/60000]\n",
            "loss : 0.284158 [51200/60000]\n",
            "loss : 0.335940 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 89.0%, Avg loss: 0.3149724435736376\n",
            "\n",
            "loss : 0.389095 [    0/60000]\n",
            "loss : 0.364632 [ 6400/60000]\n",
            "loss : 0.148301 [12800/60000]\n",
            "loss : 0.283547 [19200/60000]\n",
            "loss : 0.215050 [25600/60000]\n",
            "loss : 0.328535 [32000/60000]\n",
            "loss : 0.282481 [38400/60000]\n",
            "loss : 0.229131 [44800/60000]\n",
            "loss : 0.155860 [51200/60000]\n",
            "loss : 0.331262 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 89.3%, Avg loss: 0.3058461470565181\n",
            "\n",
            "loss : 0.265250 [    0/60000]\n",
            "loss : 0.386358 [ 6400/60000]\n",
            "loss : 0.268705 [12800/60000]\n",
            "loss : 0.312567 [19200/60000]\n",
            "loss : 0.350724 [25600/60000]\n",
            "loss : 0.233437 [32000/60000]\n",
            "loss : 0.356083 [38400/60000]\n",
            "loss : 0.192769 [44800/60000]\n",
            "loss : 0.379071 [51200/60000]\n",
            "loss : 0.429001 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 89.5%, Avg loss: 0.3004643186799753\n",
            "\n",
            "loss : 0.424102 [    0/60000]\n",
            "loss : 0.377706 [ 6400/60000]\n",
            "loss : 0.286391 [12800/60000]\n",
            "loss : 0.172713 [19200/60000]\n",
            "loss : 0.320602 [25600/60000]\n",
            "loss : 0.395675 [32000/60000]\n",
            "loss : 0.308379 [38400/60000]\n",
            "loss : 0.323928 [44800/60000]\n",
            "loss : 0.300301 [51200/60000]\n",
            "loss : 0.348673 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 89.5%, Avg loss: 0.2980213417633891\n",
            "\n",
            "loss : 0.438973 [    0/60000]\n",
            "loss : 0.295277 [ 6400/60000]\n",
            "loss : 0.264250 [12800/60000]\n",
            "loss : 0.436418 [19200/60000]\n",
            "loss : 0.278290 [25600/60000]\n",
            "loss : 0.368298 [32000/60000]\n",
            "loss : 0.282968 [38400/60000]\n",
            "loss : 0.225207 [44800/60000]\n",
            "loss : 0.199858 [51200/60000]\n",
            "loss : 0.211386 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 89.9%, Avg loss: 0.2896208017270194\n",
            "\n",
            "loss : 0.218661 [    0/60000]\n",
            "loss : 0.230505 [ 6400/60000]\n",
            "loss : 0.195646 [12800/60000]\n",
            "loss : 0.402789 [19200/60000]\n",
            "loss : 0.328643 [25600/60000]\n",
            "loss : 0.304691 [32000/60000]\n",
            "loss : 0.225075 [38400/60000]\n",
            "loss : 0.110375 [44800/60000]\n",
            "loss : 0.330415 [51200/60000]\n",
            "loss : 0.216043 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 90.1%, Avg loss: 0.2851578615891781\n",
            "\n",
            "loss : 0.300357 [    0/60000]\n",
            "loss : 0.304681 [ 6400/60000]\n",
            "loss : 0.276521 [12800/60000]\n",
            "loss : 0.400034 [19200/60000]\n",
            "loss : 0.317782 [25600/60000]\n",
            "loss : 0.265348 [32000/60000]\n",
            "loss : 0.172926 [38400/60000]\n",
            "loss : 0.254218 [44800/60000]\n",
            "loss : 0.312156 [51200/60000]\n",
            "loss : 0.247682 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 90.2%, Avg loss: 0.2800217341623708\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feedforward Model\n",
        "class NoBatchNormMLP(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NoBatchNormMLP, self).__init__()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    outputs = self.linear_relu_stack(x)\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "pJz1sEiR7pKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_batch_norm_model = NoBatchNormMLP().to(device)\n",
        "optimizer = torch.optim.SGD(no_batch_norm_model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "rtewZnBpGp1P"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for batch_idx, (X_train, y_train) in enumerate(train_dataloader):\n",
        "    # Train\n",
        "    no_batch_norm_model.train()\n",
        "    optimizer.zero_grad()\n",
        "    X_train = X_train.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "    pred = no_batch_norm_model(X_train)\n",
        "    loss = criterion(pred, y_train)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if batch_idx % 100 == 0:\n",
        "      loss, current = loss.item(), batch_idx * len(X_train)\n",
        "      print(f\"loss : {loss::>7f} [{current:>5d}/{len(train_dataloader.dataset):>5d}]\")\n",
        "  \n",
        "  test_loss, correct = 0,0\n",
        "  no_batch_norm_model.eval()\n",
        "  with torch.no_grad():\n",
        "    for X_test,y_test in test_dataloader:\n",
        "      X_test = X_test.to(device)\n",
        "      y_test = y_test.to(device)\n",
        "      pred = no_batch_norm_model(X_test)\n",
        "      test_loss += criterion(pred,y_test).item()\n",
        "      correct += (pred.argmax(1) == y_test).type(torch.float).sum().item()\n",
        "    test_loss /= len(test_dataloader)\n",
        "    correct /= len(test_dataloader.dataset)\n",
        "    print(f\"Test Error:\\n Accurancy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8}\\n\")"
      ],
      "metadata": {
        "id": "A41p2sWKG_Y-",
        "outputId": "4bcd6258-5583-4047-eb60-5c66cae3c541",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 2.310309 [    0/60000]\n",
            "loss : 2.305356 [ 6400/60000]\n",
            "loss : 2.292759 [12800/60000]\n",
            "loss : 2.310225 [19200/60000]\n",
            "loss : 2.306816 [25600/60000]\n",
            "loss : 2.302006 [32000/60000]\n",
            "loss : 2.307741 [38400/60000]\n",
            "loss : 2.310967 [44800/60000]\n",
            "loss : 2.315747 [51200/60000]\n",
            "loss : 2.304843 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.305101663443693\n",
            "\n",
            "loss : 2.303912 [    0/60000]\n",
            "loss : 2.308083 [ 6400/60000]\n",
            "loss : 2.297886 [12800/60000]\n",
            "loss : 2.304216 [19200/60000]\n",
            "loss : 2.303290 [25600/60000]\n",
            "loss : 2.311324 [32000/60000]\n",
            "loss : 2.303388 [38400/60000]\n",
            "loss : 2.302209 [44800/60000]\n",
            "loss : 2.307238 [51200/60000]\n",
            "loss : 2.288414 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.3050551915624338\n",
            "\n",
            "loss : 2.294962 [    0/60000]\n",
            "loss : 2.305453 [ 6400/60000]\n",
            "loss : 2.315350 [12800/60000]\n",
            "loss : 2.315060 [19200/60000]\n",
            "loss : 2.301724 [25600/60000]\n",
            "loss : 2.318624 [32000/60000]\n",
            "loss : 2.296133 [38400/60000]\n",
            "loss : 2.304667 [44800/60000]\n",
            "loss : 2.304796 [51200/60000]\n",
            "loss : 2.309886 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.305120864491554\n",
            "\n",
            "loss : 2.298131 [    0/60000]\n",
            "loss : 2.294574 [ 6400/60000]\n",
            "loss : 2.292402 [12800/60000]\n",
            "loss : 2.309659 [19200/60000]\n",
            "loss : 2.300921 [25600/60000]\n",
            "loss : 2.301348 [32000/60000]\n",
            "loss : 2.309780 [38400/60000]\n",
            "loss : 2.296532 [44800/60000]\n",
            "loss : 2.307143 [51200/60000]\n",
            "loss : 2.303339 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.305043583462952\n",
            "\n",
            "loss : 2.306480 [    0/60000]\n",
            "loss : 2.304649 [ 6400/60000]\n",
            "loss : 2.294956 [12800/60000]\n",
            "loss : 2.307242 [19200/60000]\n",
            "loss : 2.305250 [25600/60000]\n",
            "loss : 2.297618 [32000/60000]\n",
            "loss : 2.306847 [38400/60000]\n",
            "loss : 2.309825 [44800/60000]\n",
            "loss : 2.314102 [51200/60000]\n",
            "loss : 2.298502 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.305182643756745\n",
            "\n",
            "loss : 2.307160 [    0/60000]\n",
            "loss : 2.296687 [ 6400/60000]\n",
            "loss : 2.300176 [12800/60000]\n",
            "loss : 2.293149 [19200/60000]\n",
            "loss : 2.302660 [25600/60000]\n",
            "loss : 2.293417 [32000/60000]\n",
            "loss : 2.312254 [38400/60000]\n",
            "loss : 2.288036 [44800/60000]\n",
            "loss : 2.304998 [51200/60000]\n",
            "loss : 2.316710 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.305104173672427\n",
            "\n",
            "loss : 2.305043 [    0/60000]\n",
            "loss : 2.298118 [ 6400/60000]\n",
            "loss : 2.310548 [12800/60000]\n",
            "loss : 2.303234 [19200/60000]\n",
            "loss : 2.304033 [25600/60000]\n",
            "loss : 2.296847 [32000/60000]\n",
            "loss : 2.305241 [38400/60000]\n",
            "loss : 2.293158 [44800/60000]\n",
            "loss : 2.295046 [51200/60000]\n",
            "loss : 2.303504 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.305068456443252\n",
            "\n",
            "loss : 2.294339 [    0/60000]\n",
            "loss : 2.301738 [ 6400/60000]\n",
            "loss : 2.297983 [12800/60000]\n",
            "loss : 2.320928 [19200/60000]\n",
            "loss : 2.305974 [25600/60000]\n",
            "loss : 2.294878 [32000/60000]\n",
            "loss : 2.311438 [38400/60000]\n",
            "loss : 2.296299 [44800/60000]\n",
            "loss : 2.302957 [51200/60000]\n",
            "loss : 2.315146 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.3050149762706393\n",
            "\n",
            "loss : 2.302559 [    0/60000]\n",
            "loss : 2.301608 [ 6400/60000]\n",
            "loss : 2.299352 [12800/60000]\n",
            "loss : 2.305791 [19200/60000]\n",
            "loss : 2.303217 [25600/60000]\n",
            "loss : 2.308878 [32000/60000]\n",
            "loss : 2.298158 [38400/60000]\n",
            "loss : 2.322239 [44800/60000]\n",
            "loss : 2.299090 [51200/60000]\n",
            "loss : 2.304412 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.3050163566686543\n",
            "\n",
            "loss : 2.321797 [    0/60000]\n",
            "loss : 2.290698 [ 6400/60000]\n",
            "loss : 2.303936 [12800/60000]\n",
            "loss : 2.297617 [19200/60000]\n",
            "loss : 2.311367 [25600/60000]\n",
            "loss : 2.313311 [32000/60000]\n",
            "loss : 2.298613 [38400/60000]\n",
            "loss : 2.297278 [44800/60000]\n",
            "loss : 2.296144 [51200/60000]\n",
            "loss : 2.307234 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.3050388925394434\n",
            "\n",
            "loss : 2.305902 [    0/60000]\n",
            "loss : 2.304716 [ 6400/60000]\n",
            "loss : 2.306629 [12800/60000]\n",
            "loss : 2.326210 [19200/60000]\n",
            "loss : 2.308107 [25600/60000]\n",
            "loss : 2.295335 [32000/60000]\n",
            "loss : 2.296604 [38400/60000]\n",
            "loss : 2.311559 [44800/60000]\n",
            "loss : 2.302561 [51200/60000]\n",
            "loss : 2.293037 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.3050495393716606\n",
            "\n",
            "loss : 2.294595 [    0/60000]\n",
            "loss : 2.309524 [ 6400/60000]\n",
            "loss : 2.313126 [12800/60000]\n",
            "loss : 2.295537 [19200/60000]\n",
            "loss : 2.304557 [25600/60000]\n",
            "loss : 2.294340 [32000/60000]\n",
            "loss : 2.309295 [38400/60000]\n",
            "loss : 2.297743 [44800/60000]\n",
            "loss : 2.316067 [51200/60000]\n",
            "loss : 2.292884 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.305180595179272\n",
            "\n",
            "loss : 2.302265 [    0/60000]\n",
            "loss : 2.294181 [ 6400/60000]\n",
            "loss : 2.296106 [12800/60000]\n",
            "loss : 2.301819 [19200/60000]\n",
            "loss : 2.306809 [25600/60000]\n",
            "loss : 2.304940 [32000/60000]\n",
            "loss : 2.294850 [38400/60000]\n",
            "loss : 2.300911 [44800/60000]\n",
            "loss : 2.305827 [51200/60000]\n",
            "loss : 2.309128 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.305055805072663\n",
            "\n",
            "loss : 2.312731 [    0/60000]\n",
            "loss : 2.300946 [ 6400/60000]\n",
            "loss : 2.308625 [12800/60000]\n",
            "loss : 2.306620 [19200/60000]\n",
            "loss : 2.307321 [25600/60000]\n",
            "loss : 2.304708 [32000/60000]\n",
            "loss : 2.313016 [38400/60000]\n",
            "loss : 2.305992 [44800/60000]\n",
            "loss : 2.309107 [51200/60000]\n",
            "loss : 2.287705 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.305263417541601\n",
            "\n",
            "loss : 2.304146 [    0/60000]\n",
            "loss : 2.302480 [ 6400/60000]\n",
            "loss : 2.319257 [12800/60000]\n",
            "loss : 2.310134 [19200/60000]\n",
            "loss : 2.313428 [25600/60000]\n",
            "loss : 2.310137 [32000/60000]\n",
            "loss : 2.303415 [38400/60000]\n",
            "loss : 2.314112 [44800/60000]\n",
            "loss : 2.304273 [51200/60000]\n",
            "loss : 2.290539 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.305115780253319\n",
            "\n",
            "loss : 2.305118 [    0/60000]\n",
            "loss : 2.305984 [ 6400/60000]\n",
            "loss : 2.300875 [12800/60000]\n",
            "loss : 2.318125 [19200/60000]\n",
            "loss : 2.297726 [25600/60000]\n",
            "loss : 2.288161 [32000/60000]\n",
            "loss : 2.291463 [38400/60000]\n",
            "loss : 2.312328 [44800/60000]\n",
            "loss : 2.306678 [51200/60000]\n",
            "loss : 2.295392 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.3053094657363404\n",
            "\n",
            "loss : 2.298038 [    0/60000]\n",
            "loss : 2.308128 [ 6400/60000]\n",
            "loss : 2.307245 [12800/60000]\n",
            "loss : 2.305246 [19200/60000]\n",
            "loss : 2.312266 [25600/60000]\n",
            "loss : 2.302507 [32000/60000]\n",
            "loss : 2.307505 [38400/60000]\n",
            "loss : 2.308054 [44800/60000]\n",
            "loss : 2.291000 [51200/60000]\n",
            "loss : 2.302639 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.3051423009034173\n",
            "\n",
            "loss : 2.313831 [    0/60000]\n",
            "loss : 2.311961 [ 6400/60000]\n",
            "loss : 2.316491 [12800/60000]\n",
            "loss : 2.309905 [19200/60000]\n",
            "loss : 2.312447 [25600/60000]\n",
            "loss : 2.305278 [32000/60000]\n",
            "loss : 2.306141 [38400/60000]\n",
            "loss : 2.295063 [44800/60000]\n",
            "loss : 2.293341 [51200/60000]\n",
            "loss : 2.291833 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.3049345441684603\n",
            "\n",
            "loss : 2.294381 [    0/60000]\n",
            "loss : 2.309363 [ 6400/60000]\n",
            "loss : 2.286358 [12800/60000]\n",
            "loss : 2.313692 [19200/60000]\n",
            "loss : 2.303189 [25600/60000]\n",
            "loss : 2.314161 [32000/60000]\n",
            "loss : 2.292620 [38400/60000]\n",
            "loss : 2.296348 [44800/60000]\n",
            "loss : 2.311460 [51200/60000]\n",
            "loss : 2.297100 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.3052135622425443\n",
            "\n",
            "loss : 2.308310 [    0/60000]\n",
            "loss : 2.302256 [ 6400/60000]\n",
            "loss : 2.298280 [12800/60000]\n",
            "loss : 2.318629 [19200/60000]\n",
            "loss : 2.315136 [25600/60000]\n",
            "loss : 2.306686 [32000/60000]\n",
            "loss : 2.295985 [38400/60000]\n",
            "loss : 2.317283 [44800/60000]\n",
            "loss : 2.332632 [51200/60000]\n",
            "loss : 2.286517 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 11.0%, Avg loss: 2.305153605284964\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "KXwgoaNYJSnE"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = torch.zeros(1)\n",
        "std = torch.zeros(1)\n",
        "print('==> Computing mean and std..')\n",
        "for inputs, _labels in train_dataloader:\n",
        "  for i in range(1):\n",
        "    mean[i] += inputs[:,i,:,:].mean()\n",
        "    std[i] += inputs[:,i,:,:].std()\n",
        "  mean.div_(len(train_dataloader))\n",
        "  std.div_(len(train_dataloader))\n",
        "print(mean, std)\n"
      ],
      "metadata": {
        "id": "N_tG8ZHnNPjb",
        "outputId": "75590dab-eec4-4281-8392-40c035e92701",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Computing mean and std..\n",
            "tensor([0.0003]) tensor([0.0004])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5), (0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "Zxiw4JVgHIu3"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_training_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=norm_transform,\n",
        "    target_transform=Lambda(\n",
        "        lambda y: torch.zeros(10,dtype=torch.float).scatter_(0, torch.tensor(y),value=1)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "pXkHagCHJR6U"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=norm_transform\n",
        ")"
      ],
      "metadata": {
        "id": "JGMxaZDDJmg1"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_train_dataloader = DataLoader(norm_training_data, batch_size=64, shuffle=True)\n",
        "norm_test_dataloader = DataLoader(norm_test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "gUGnOQj9JtgJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_for_norm = MLP().to(device)\n",
        "optimizer = torch.optim.SGD(model_for_norm.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "2xKh-fe_JzTK"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for batch_idx, (X_train, y_train) in enumerate(norm_train_dataloader):\n",
        "    # Train\n",
        "    model_for_norm.train()\n",
        "    optimizer.zero_grad()\n",
        "    X_train = X_train.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "    pred = model_for_norm(X_train)\n",
        "    loss = criterion(pred, y_train)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if batch_idx % 100 == 0:\n",
        "      loss, current = loss.item(), batch_idx * len(X_train)\n",
        "      print(f\"loss : {loss::>7f} [{current:>5d}/{len(norm_train_dataloader.dataset):>5d}]\")\n",
        "  \n",
        "  test_loss, correct = 0,0\n",
        "  model_for_norm.eval()\n",
        "  with torch.no_grad():\n",
        "    for X_test,y_test in norm_test_dataloader:\n",
        "      X_test = X_test.to(device)\n",
        "      y_test = y_test.to(device)\n",
        "      pred = model_for_norm(X_test)\n",
        "      test_loss += criterion(pred,y_test).item()\n",
        "      correct += (pred.argmax(1) == y_test).type(torch.float).sum().item()\n",
        "    test_loss /= len(norm_test_dataloader)\n",
        "    correct /= len(norm_test_dataloader.dataset)\n",
        "    print(f\"Test Error:\\n Accurancy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8}\\n\")\n"
      ],
      "metadata": {
        "id": "MjopAAizJ-HT",
        "outputId": "1d77e109-db66-4381-f844-19c40daf44e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 2.368590 [    0/60000]\n",
            "loss : 1.329848 [ 6400/60000]\n",
            "loss : 1.207564 [12800/60000]\n",
            "loss : 0.981357 [19200/60000]\n",
            "loss : 0.874484 [25600/60000]\n",
            "loss : 1.017581 [32000/60000]\n",
            "loss : 0.909328 [38400/60000]\n",
            "loss : 0.761604 [44800/60000]\n",
            "loss : 0.745831 [51200/60000]\n",
            "loss : 0.774504 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 78.6%, Avg loss: 0.6703777005718012\n",
            "\n",
            "loss : 0.644553 [    0/60000]\n",
            "loss : 0.640675 [ 6400/60000]\n",
            "loss : 0.573136 [12800/60000]\n",
            "loss : 0.469450 [19200/60000]\n",
            "loss : 0.618740 [25600/60000]\n",
            "loss : 0.506961 [32000/60000]\n",
            "loss : 0.418471 [38400/60000]\n",
            "loss : 0.502442 [44800/60000]\n",
            "loss : 0.439745 [51200/60000]\n",
            "loss : 0.558976 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 81.9%, Avg loss: 0.5497547488683349\n",
            "\n",
            "loss : 0.570003 [    0/60000]\n",
            "loss : 0.691324 [ 6400/60000]\n",
            "loss : 0.468275 [12800/60000]\n",
            "loss : 0.554054 [19200/60000]\n",
            "loss : 0.697378 [25600/60000]\n",
            "loss : 0.485486 [32000/60000]\n",
            "loss : 0.497167 [38400/60000]\n",
            "loss : 0.534155 [44800/60000]\n",
            "loss : 0.362863 [51200/60000]\n",
            "loss : 0.559801 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 83.0%, Avg loss: 0.49800730017340106\n",
            "\n",
            "loss : 0.347380 [    0/60000]\n",
            "loss : 0.571369 [ 6400/60000]\n",
            "loss : 0.431250 [12800/60000]\n",
            "loss : 0.484125 [19200/60000]\n",
            "loss : 0.414939 [25600/60000]\n",
            "loss : 0.470321 [32000/60000]\n",
            "loss : 0.557494 [38400/60000]\n",
            "loss : 0.504552 [44800/60000]\n",
            "loss : 0.323225 [51200/60000]\n",
            "loss : 0.348792 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 84.0%, Avg loss: 0.4632285204093168\n",
            "\n",
            "loss : 0.434383 [    0/60000]\n",
            "loss : 0.283117 [ 6400/60000]\n",
            "loss : 0.379679 [12800/60000]\n",
            "loss : 0.478342 [19200/60000]\n",
            "loss : 0.432306 [25600/60000]\n",
            "loss : 0.408768 [32000/60000]\n",
            "loss : 0.307348 [38400/60000]\n",
            "loss : 0.381776 [44800/60000]\n",
            "loss : 0.421141 [51200/60000]\n",
            "loss : 0.340130 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 84.6%, Avg loss: 0.44542404164554206\n",
            "\n",
            "loss : 0.387817 [    0/60000]\n",
            "loss : 0.545379 [ 6400/60000]\n",
            "loss : 0.453798 [12800/60000]\n",
            "loss : 0.501061 [19200/60000]\n",
            "loss : 0.457410 [25600/60000]\n",
            "loss : 0.378981 [32000/60000]\n",
            "loss : 0.411956 [38400/60000]\n",
            "loss : 0.325350 [44800/60000]\n",
            "loss : 0.451601 [51200/60000]\n",
            "loss : 0.447197 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 85.0%, Avg loss: 0.42762810798587314\n",
            "\n",
            "loss : 0.310022 [    0/60000]\n",
            "loss : 0.343843 [ 6400/60000]\n",
            "loss : 0.364424 [12800/60000]\n",
            "loss : 0.401819 [19200/60000]\n",
            "loss : 0.407956 [25600/60000]\n",
            "loss : 0.347688 [32000/60000]\n",
            "loss : 0.345298 [38400/60000]\n",
            "loss : 0.445095 [44800/60000]\n",
            "loss : 0.327863 [51200/60000]\n",
            "loss : 0.360059 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 85.6%, Avg loss: 0.4152759204434741\n",
            "\n",
            "loss : 0.518688 [    0/60000]\n",
            "loss : 0.516637 [ 6400/60000]\n",
            "loss : 0.486468 [12800/60000]\n",
            "loss : 0.505698 [19200/60000]\n",
            "loss : 0.508925 [25600/60000]\n",
            "loss : 0.287741 [32000/60000]\n",
            "loss : 0.441768 [38400/60000]\n",
            "loss : 0.511555 [44800/60000]\n",
            "loss : 0.335838 [51200/60000]\n",
            "loss : 0.349121 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 85.6%, Avg loss: 0.404735425285473\n",
            "\n",
            "loss : 0.287556 [    0/60000]\n",
            "loss : 0.223080 [ 6400/60000]\n",
            "loss : 0.311723 [12800/60000]\n",
            "loss : 0.585890 [19200/60000]\n",
            "loss : 0.381358 [25600/60000]\n",
            "loss : 0.301473 [32000/60000]\n",
            "loss : 0.475208 [38400/60000]\n",
            "loss : 0.392301 [44800/60000]\n",
            "loss : 0.399798 [51200/60000]\n",
            "loss : 0.362181 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 85.9%, Avg loss: 0.3969196321288492\n",
            "\n",
            "loss : 0.484121 [    0/60000]\n",
            "loss : 0.228021 [ 6400/60000]\n",
            "loss : 0.314898 [12800/60000]\n",
            "loss : 0.382688 [19200/60000]\n",
            "loss : 0.388659 [25600/60000]\n",
            "loss : 0.348692 [32000/60000]\n",
            "loss : 0.405979 [38400/60000]\n",
            "loss : 0.380786 [44800/60000]\n",
            "loss : 0.372636 [51200/60000]\n",
            "loss : 0.346443 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 86.1%, Avg loss: 0.3929278759440039\n",
            "\n",
            "loss : 0.339764 [    0/60000]\n",
            "loss : 0.309215 [ 6400/60000]\n",
            "loss : 0.348173 [12800/60000]\n",
            "loss : 0.377262 [19200/60000]\n",
            "loss : 0.329937 [25600/60000]\n",
            "loss : 0.375809 [32000/60000]\n",
            "loss : 0.607094 [38400/60000]\n",
            "loss : 0.215328 [44800/60000]\n",
            "loss : 0.423501 [51200/60000]\n",
            "loss : 0.394047 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 86.4%, Avg loss: 0.3844231434498623\n",
            "\n",
            "loss : 0.362819 [    0/60000]\n",
            "loss : 0.269253 [ 6400/60000]\n",
            "loss : 0.383466 [12800/60000]\n",
            "loss : 0.353124 [19200/60000]\n",
            "loss : 0.511347 [25600/60000]\n",
            "loss : 0.305076 [32000/60000]\n",
            "loss : 0.366270 [38400/60000]\n",
            "loss : 0.342581 [44800/60000]\n",
            "loss : 0.378885 [51200/60000]\n",
            "loss : 0.290062 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 86.6%, Avg loss: 0.3805517501132503\n",
            "\n",
            "loss : 0.388298 [    0/60000]\n",
            "loss : 0.246722 [ 6400/60000]\n",
            "loss : 0.292633 [12800/60000]\n",
            "loss : 0.361520 [19200/60000]\n",
            "loss : 0.382923 [25600/60000]\n",
            "loss : 0.277950 [32000/60000]\n",
            "loss : 0.263915 [38400/60000]\n",
            "loss : 0.365870 [44800/60000]\n",
            "loss : 0.285418 [51200/60000]\n",
            "loss : 0.421505 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 86.8%, Avg loss: 0.374096735362794\n",
            "\n",
            "loss : 0.407527 [    0/60000]\n",
            "loss : 0.246840 [ 6400/60000]\n",
            "loss : 0.281160 [12800/60000]\n",
            "loss : 0.411124 [19200/60000]\n",
            "loss : 0.407790 [25600/60000]\n",
            "loss : 0.302671 [32000/60000]\n",
            "loss : 0.364247 [38400/60000]\n",
            "loss : 0.207705 [44800/60000]\n",
            "loss : 0.308819 [51200/60000]\n",
            "loss : 0.428458 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 86.9%, Avg loss: 0.37373567244429495\n",
            "\n",
            "loss : 0.274216 [    0/60000]\n",
            "loss : 0.289081 [ 6400/60000]\n",
            "loss : 0.300686 [12800/60000]\n",
            "loss : 0.412452 [19200/60000]\n",
            "loss : 0.478878 [25600/60000]\n",
            "loss : 0.260793 [32000/60000]\n",
            "loss : 0.307209 [38400/60000]\n",
            "loss : 0.271769 [44800/60000]\n",
            "loss : 0.174903 [51200/60000]\n",
            "loss : 0.172630 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 87.1%, Avg loss: 0.36589771034611257\n",
            "\n",
            "loss : 0.375547 [    0/60000]\n",
            "loss : 0.314394 [ 6400/60000]\n",
            "loss : 0.361158 [12800/60000]\n",
            "loss : 0.426088 [19200/60000]\n",
            "loss : 0.300747 [25600/60000]\n",
            "loss : 0.495699 [32000/60000]\n",
            "loss : 0.429116 [38400/60000]\n",
            "loss : 0.368133 [44800/60000]\n",
            "loss : 0.451281 [51200/60000]\n",
            "loss : 0.204609 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 87.2%, Avg loss: 0.3653707676062918\n",
            "\n",
            "loss : 0.272938 [    0/60000]\n",
            "loss : 0.342083 [ 6400/60000]\n",
            "loss : 0.377835 [12800/60000]\n",
            "loss : 0.170955 [19200/60000]\n",
            "loss : 0.279566 [25600/60000]\n",
            "loss : 0.304805 [32000/60000]\n",
            "loss : 0.361781 [38400/60000]\n",
            "loss : 0.175030 [44800/60000]\n",
            "loss : 0.214394 [51200/60000]\n",
            "loss : 0.315857 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 87.5%, Avg loss: 0.35707164717138196\n",
            "\n",
            "loss : 0.489300 [    0/60000]\n",
            "loss : 0.325442 [ 6400/60000]\n",
            "loss : 0.374619 [12800/60000]\n",
            "loss : 0.182812 [19200/60000]\n",
            "loss : 0.244630 [25600/60000]\n",
            "loss : 0.362238 [32000/60000]\n",
            "loss : 0.236168 [38400/60000]\n",
            "loss : 0.218061 [44800/60000]\n",
            "loss : 0.330181 [51200/60000]\n",
            "loss : 0.248384 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 87.7%, Avg loss: 0.35373169304743696\n",
            "\n",
            "loss : 0.207404 [    0/60000]\n",
            "loss : 0.399864 [ 6400/60000]\n",
            "loss : 0.217214 [12800/60000]\n",
            "loss : 0.407889 [19200/60000]\n",
            "loss : 0.216841 [25600/60000]\n",
            "loss : 0.506080 [32000/60000]\n",
            "loss : 0.230691 [38400/60000]\n",
            "loss : 0.320331 [44800/60000]\n",
            "loss : 0.258616 [51200/60000]\n",
            "loss : 0.310904 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 87.7%, Avg loss: 0.3531513607995525\n",
            "\n",
            "loss : 0.296223 [    0/60000]\n",
            "loss : 0.237593 [ 6400/60000]\n",
            "loss : 0.320859 [12800/60000]\n",
            "loss : 0.251312 [19200/60000]\n",
            "loss : 0.335943 [25600/60000]\n",
            "loss : 0.293315 [32000/60000]\n",
            "loss : 0.228836 [38400/60000]\n",
            "loss : 0.341904 [44800/60000]\n",
            "loss : 0.490090 [51200/60000]\n",
            "loss : 0.247066 [57600/60000]\n",
            "Test Error:\n",
            " Accurancy: 87.7%, Avg loss: 0.3503423879860313\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "metadata": {
        "id": "7VzgPKgOKDYG"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784')\n",
        "x_data = mnist.data.astype('float32')\n",
        "y_data = mnist.target.astype(int)"
      ],
      "metadata": {
        "id": "pnrjCwhcsH1B"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "X_train, X_test = torch.tensor(X_train.values), torch.tensor(X_test.values)\n",
        "y_train, y_test = torch.tensor(y_train.values), torch.tensor(y_test.values)\n",
        "X_train = X_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "UIlD8qEJsJZ8",
        "outputId": "c1025d58-f404-46d1-e150-04cbd9b77925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([56000, 784])\n",
            "torch.Size([14000, 784])\n",
            "torch.Size([56000])\n",
            "torch.Size([14000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GprgFI7QsKRB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "mnist.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}