{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Basic\n",
        "## install"
      ],
      "metadata": {
        "id": "P1I7sU89tO0K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fX8VvQ0rtbFA",
        "outputId": "0477a097-2b19-44fe-9508-ef2b27b570ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "# torch는 기본으로 설치 되어 있다.\n",
        "# !를 통해서 shell script 명령어를 사용할 수 있다.\n",
        "!pip install torch\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor"
      ],
      "metadata": {
        "id": "VkXDDyr9tHdw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ScxSuVa4tbFD",
        "outputId": "d30d4a57-6deb-4d0b-efb7-6f4c466a47af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.zeros(4) :  tensor([0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "x = torch.zeros(4) # 0으로 채워진 길이가 4인 1차원 Tensor 생성\n",
        "print(\"torch.zeros(4) : \", x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.zeros([2,3]) # 0으로 채워진 길이가 2와 3인 2차원 Tensor 생성\n",
        "print(\"torch.zeros([2,3]) : \\n\", y)"
      ],
      "metadata": {
        "id": "5Zj-wKKFqdjd",
        "outputId": "413303d4-c794-415d-a8fa-ed02bab34344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.zeros([2,3]) : \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.zeros([2,3,1]) # 0으로 채워진 길이가 2와 3,1인 3차원 Tensor 생성\n",
        "print(\"torch.zeros([2,3,1]) : \\n\", z)"
      ],
      "metadata": {
        "id": "O35SpYe_qsEE",
        "outputId": "bccf6a6d-85fd-4bc1-bd61-b313fa51b931",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.zeros([2,3,1]) : \n",
            " tensor([[[0.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.],\n",
            "         [0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.randn([2,3])\n",
        "print(f\"tensor :\\n{tensor}\") # 차원 확인\n",
        "# Attributes of tensor\n",
        "print(f\"Shape of tensor : {tensor.shape}\") # 차원 확인\n",
        "print(f\"Datatype of tensor : {tensor.dtype}\") # 데이터타입 확인\n",
        "print(f\"Device tensor of stored on : {tensor.device}\") # 기기 확인\n",
        "# Standard numpy-like indexing and slicing\n",
        "print(f\"First row : {tensor[0]}\") # indexing을 이용한 데이터 접근\n",
        "# :은 작성된 차원을 전부 사용, [:,0] => 1차원 전부와 2차원 데이터 중 index가 0인 값.\n",
        "print(f\"First column : {tensor[:,0]}\")\n",
        "# ...은 직접 작성된 차원을 제외한 차원을 원본 그대로 사용\n",
        "# [..., -1]은 마지막 차원을 제외하고 모든 차원의 데이터 전부와 마지막 차원의 index가 -1(마지막)인 값\n",
        "print(f\"Last column : {tensor[...,-1]}\")\n",
        "\n",
        "tensor[:,1]=0\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "_gLON3l-sHCk",
        "outputId": "a680f59c-e420-48e8-d9ed-f379d6edcc8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor :\n",
            "tensor([[ 1.0137,  0.2215,  1.0852],\n",
            "        [-0.0507,  1.2595, -1.6198]])\n",
            "Shape of tensor : torch.Size([2, 3])\n",
            "Datatype of tensor : torch.float32\n",
            "Device tensor of stored on : cpu\n",
            "First row : tensor([1.0137, 0.2215, 1.0852])\n",
            "First column : tensor([ 1.0137, -0.0507])\n",
            "Last column : tensor([ 1.0852, -1.6198])\n",
            "tensor([[ 1.0137,  0.0000,  1.0852],\n",
            "        [-0.0507,  0.0000, -1.6198]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vzCwkx7iuJ5Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Tensor\n",
        "##### Directly initializing\n",
        "tensor_one=torch.tensor([[5,8,6],[8,4,5]], dtype=torch.float64, requires_grad=True)\n",
        "print(tensor_one)\n",
        "##### Randomly initializing tensor with shape of [2,3]\n",
        "tensor_two=torch.randn(tensor_one.shape, dtype=torch.float64, requires_grad=True)\n",
        "print(tensor_two)"
      ],
      "metadata": {
        "id": "6ys10BHNvRpq",
        "outputId": "ff9ffbd1-bb2f-447a-f551-85ada27c6a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5., 8., 6.],\n",
            "        [8., 4., 5.]], dtype=torch.float64, requires_grad=True)\n",
            "tensor([[ 0.4452,  1.0368,  0.5283],\n",
            "        [-0.3313, -0.1057, -0.1822]], dtype=torch.float64, requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Arithmetic operations\n",
        "y1 = torch.add(tensor_one, tensor_two)\n",
        "y2 = tensor_one+tensor_two\n",
        "print(y1)\n",
        "print(y2)"
      ],
      "metadata": {
        "id": "ReQqTMKvv_Ny",
        "outputId": "d3568378-4271-4d11-b89b-adb06916f978",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5.4452, 9.0368, 6.5283],\n",
            "        [7.6687, 3.8943, 4.8178]], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor([[5.4452, 9.0368, 6.5283],\n",
            "        [7.6687, 3.8943, 4.8178]], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = torch.mul(tensor_one, tensor_two)\n",
        "y2 = tensor_one*tensor_two\n",
        "print(y1)\n",
        "print(y2)"
      ],
      "metadata": {
        "id": "p_Eq67RlwST0",
        "outputId": "5c9b9444-fd53-4fc3-d8c3-3a03e538712c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.2258,  8.2946,  3.1700],\n",
            "        [-2.6505, -0.4230, -0.9108]], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n",
            "tensor([[ 2.2258,  8.2946,  3.1700],\n",
            "        [-2.6505, -0.4230, -0.9108]], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = torch.matmul(tensor_one, tensor_two.T)\n",
        "y2 = tensor_one@tensor_two.T\n",
        "print(y1)\n",
        "print(y2)"
      ],
      "metadata": {
        "id": "GLWz_oOswYmD",
        "outputId": "abd92dd6-26dd-4572-af4b-099640ac2dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13.6904, -3.5955],\n",
            "        [10.3502, -3.9843]], dtype=torch.float64, grad_fn=<MmBackward0>)\n",
            "tensor([[13.6904, -3.5955],\n",
            "        [10.3502, -3.9843]], dtype=torch.float64, grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad = True: tensor 연산할 때, gradient를 자동으로 트랙킹함.\n",
        "# backwordL gradient 계산\n",
        "x = torch.tensor([5], dtype=torch.float64, requires_grad=True)\n",
        "y = torch.tensor([2], dtype=torch.float64, requires_grad=True)\n",
        "z = x*y\n",
        "z.backward()\n",
        "print(x.grad)\n",
        "print(y.grad)"
      ],
      "metadata": {
        "id": "gRmKUiugwbvK",
        "outputId": "a3179440-d3d3-4c50-9223-1921c386d1aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.], dtype=torch.float64)\n",
            "tensor([5.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor -> numpy 혹은 numpy -> tensor를 할 경우,\n",
        "# tensor와 numpy array가 cpu에서 동작할 경우 메모리 공유\n",
        "tensor = torch.ones(5)\n",
        "print(f\"tensor:{tensor}\")\n",
        "numpy_array = tensor.numpy()\n",
        "print(f\"numpy_array:{numpy_array}\")\n",
        "\n",
        "tensor.add_(3) # in-place add\n",
        "print(f\"tensor:{tensor}\")\n",
        "print(f\"numpy_array:{numpy_array}\")\n",
        "\n",
        "tensor = tensor.add(3) # add 후 새로운 객체를 할당\n",
        "print(f\"tensor:{tensor}\")\n",
        "print(f\"numpy_array:{numpy_array}\")"
      ],
      "metadata": {
        "id": "UsRyGxSsw564",
        "outputId": "d8609327-a779-4fa1-ef52-a3154fc4cb7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor:tensor([1., 1., 1., 1., 1.])\n",
            "numpy_array:[1. 1. 1. 1. 1.]\n",
            "tensor:tensor([4., 4., 4., 4., 4.])\n",
            "numpy_array:[4. 4. 4. 4. 4.]\n",
            "tensor:tensor([7., 7., 7., 7., 7.])\n",
            "numpy_array:[4. 4. 4. 4. 4.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## torch.view\n",
        "x1 = torch.randn(4,5)\n",
        "x2 = x1.view(20)\n",
        "x3 = x1.view(2,-1) # -1은 자동 할당\n",
        "x4 = x1.view(2,2,5)\n",
        "print(x1.shape)\n",
        "print(x2.shape)\n",
        "print(x3.shape)\n",
        "print(x4.shape)"
      ],
      "metadata": {
        "id": "FlI8uW3_BuuW",
        "outputId": "ba0a9c4e-7fa4-4fe0-96eb-5675d8468128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 5])\n",
            "torch.Size([20])\n",
            "torch.Size([2, 10])\n",
            "torch.Size([2, 2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4x5는 총 20개의 element를 가지고 있는데 \n",
        "# 정확하게 나눌 수 없는 값으로 shape을 변경한다면?\n",
        "# x5 = x1.view(3,-1)\n",
        "# RuntimeError: shape '[3, -1]' is invalid for input of size 20\n",
        "# RuntimeError 발생!"
      ],
      "metadata": {
        "id": "sWHj7M3eF9tp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# squeeze : 자원 축소\n",
        "x1 = torch.randn(3,1,1,3)\n",
        "print(x1, x1.shape)\n",
        "x2 = x1.squeeze() # 해당 차원의 데이터 길이가 1인 차원들을 삭제시킴.\n",
        "print(x2, x2.shape)"
      ],
      "metadata": {
        "id": "RifAlXuQGHzO",
        "outputId": "22a8aaef-ddd4-447c-c0f6-aa052c891a85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.0391, -0.8724,  0.8961]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9636, -1.0021,  0.7613]]],\n",
            "\n",
            "\n",
            "        [[[-0.8230, -0.7096, -0.3206]]]]) torch.Size([3, 1, 1, 3])\n",
            "tensor([[ 0.0391, -0.8724,  0.8961],\n",
            "        [ 0.9636, -1.0021,  0.7613],\n",
            "        [-0.8230, -0.7096, -0.3206]]) torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unsqueeze : 자원 확대\n",
        "x1 = torch.randn(3,1,3)\n",
        "print(x1, x1.shape)\n",
        "x2 = x1.unsqueeze(dim=0) # dim의 값에 해당하는 차원을 데이터 길이 1로 추가해줌.\n",
        "print(x2, x2.shape)"
      ],
      "metadata": {
        "id": "QEXF_exMHGzg",
        "outputId": "f3c7b4dd-32e1-4ec3-cef4-821545e014fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.6211,  1.1688,  0.4561]],\n",
            "\n",
            "        [[-1.0033,  0.3040, -1.6314]],\n",
            "\n",
            "        [[ 0.4042, -0.4986,  1.1786]]]) torch.Size([3, 1, 3])\n",
            "tensor([[[[-0.6211,  1.1688,  0.4561]],\n",
            "\n",
            "         [[-1.0033,  0.3040, -1.6314]],\n",
            "\n",
            "         [[ 0.4042, -0.4986,  1.1786]]]]) torch.Size([1, 3, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stack: 새로운 차원으로 tensor를 붙임\n",
        "x1 = torch.randn([1,2,3])\n",
        "x2 = torch.randn([1,2,3])\n",
        "print(x1)\n",
        "print(x2)\n",
        "\n",
        "x3 = torch.stack([x1,x2]) # default dim = 0\n",
        "print(x3, x3.shape)\n",
        "\n",
        "x3 = torch.stack([x1,x2], dim=1)\n",
        "print(x3, x3.shape)\n",
        "\n",
        "x3 = torch.stack([x1,x2], dim=2)\n",
        "print(x3, x3.shape)\n",
        "\n",
        "x3 = torch.stack([x1,x2], dim=3)\n",
        "print(x3, x3.shape)"
      ],
      "metadata": {
        "id": "IxxXi3NfHux2",
        "outputId": "972fe3c7-1f84-457b-ef70-d55d697f453a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0271,  0.4221,  1.1858],\n",
            "         [ 0.5947, -0.2850,  0.2684]]])\n",
            "tensor([[[-0.8598, -1.0454,  0.5261],\n",
            "         [ 0.1927, -1.9400,  0.0603]]])\n",
            "tensor([[[[ 0.0271,  0.4221,  1.1858],\n",
            "          [ 0.5947, -0.2850,  0.2684]]],\n",
            "\n",
            "\n",
            "        [[[-0.8598, -1.0454,  0.5261],\n",
            "          [ 0.1927, -1.9400,  0.0603]]]]) torch.Size([2, 1, 2, 3])\n",
            "tensor([[[[ 0.0271,  0.4221,  1.1858],\n",
            "          [ 0.5947, -0.2850,  0.2684]],\n",
            "\n",
            "         [[-0.8598, -1.0454,  0.5261],\n",
            "          [ 0.1927, -1.9400,  0.0603]]]]) torch.Size([1, 2, 2, 3])\n",
            "tensor([[[[ 0.0271,  0.4221,  1.1858],\n",
            "          [-0.8598, -1.0454,  0.5261]],\n",
            "\n",
            "         [[ 0.5947, -0.2850,  0.2684],\n",
            "          [ 0.1927, -1.9400,  0.0603]]]]) torch.Size([1, 2, 2, 3])\n",
            "tensor([[[[ 0.0271, -0.8598],\n",
            "          [ 0.4221, -1.0454],\n",
            "          [ 1.1858,  0.5261]],\n",
            "\n",
            "         [[ 0.5947,  0.1927],\n",
            "          [-0.2850, -1.9400],\n",
            "          [ 0.2684,  0.0603]]]]) torch.Size([1, 2, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cat : 주어진 차원에서 tensor를 붙임\n",
        "x3 = torch.cat([x1, x2])  # default dim = 0\n",
        "print(x3, x3.shape)\n",
        "\n",
        "x3 = torch.cat([x1, x2], dim=1)\n",
        "print(x3, x3.shape)\n",
        "\n",
        "x3 = torch.cat([x1, x2], dim=2)\n",
        "print(x3, x3.shape)"
      ],
      "metadata": {
        "id": "GCh-nuGeIGP-",
        "outputId": "b5331438-75af-4904-9dc5-58bb4969a145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0271,  0.4221,  1.1858],\n",
            "         [ 0.5947, -0.2850,  0.2684]],\n",
            "\n",
            "        [[-0.8598, -1.0454,  0.5261],\n",
            "         [ 0.1927, -1.9400,  0.0603]]]) torch.Size([2, 2, 3])\n",
            "tensor([[[ 0.0271,  0.4221,  1.1858],\n",
            "         [ 0.5947, -0.2850,  0.2684],\n",
            "         [-0.8598, -1.0454,  0.5261],\n",
            "         [ 0.1927, -1.9400,  0.0603]]]) torch.Size([1, 4, 3])\n",
            "tensor([[[ 0.0271,  0.4221,  1.1858, -0.8598, -1.0454,  0.5261],\n",
            "         [ 0.5947, -0.2850,  0.2684,  0.1927, -1.9400,  0.0603]]]) torch.Size([1, 2, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chunk: 주어진 차원기준 tensor를 n개의 그룹으로 나눔(n등분 50 / n=10 -> 5)\n",
        "x1 = torch.stack([torch.ones(6), torch.zeros(6)])\n",
        "print(x1, x1.shape)\n",
        "x2, x3 = torch.chunk(x1,2,dim=0)\n",
        "print(x2, x2.shape)\n",
        "x2, x3 = torch.chunk(x1,2,dim=1)\n",
        "print(x2, x2.shape)"
      ],
      "metadata": {
        "id": "tSuGFMykIYx9",
        "outputId": "fd3fa3bd-a859-49a6-c791-240477525ad4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0.]]) torch.Size([2, 6])\n",
            "tensor([[1., 1., 1., 1., 1., 1.]]) torch.Size([1, 6])\n",
            "tensor([[1., 1., 1.],\n",
            "        [0., 0., 0.]]) torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split: 주어진 차원기준 tensor를 n개씩 구성된 그룹으로 나눔(n개 그룹 50 / 10 -> n=5)\n",
        "x2, x3 = torch.split(x1,1,dim=0)\n",
        "print(x2, x2.shape)\n",
        "x2, x3, x4 = torch.split(x1,2,dim=1)\n",
        "print(x2, x2.shape)"
      ],
      "metadata": {
        "id": "6s-DFf82p1eW",
        "outputId": "a25f0275-1448-4ee2-8743-a6aab0e905b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1., 1., 1.]]) torch.Size([1, 6])\n",
            "tensor([[1., 1.],\n",
            "        [0., 0.]]) torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor를 gpu로 이동\n",
        "x1 = torch.randn(2,3)\n",
        "print(x1)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "x1 = x1.to(device)\n",
        "x2 = torch.randn(2,3, device=device)\n",
        "x3 = torch.randn(2,3)\n",
        "print(x1+x2)\n",
        "print(x2+x3) # tensor가 같은 위치에 있지 않아서 에러 발생(x2 위치 : gpu(cuda), x3 위치 : cpu)\n",
        "# RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
      ],
      "metadata": {
        "id": "vBKIxqqQqA5r",
        "outputId": "2422d434-4c72-4b0e-b6ba-0bdcef5f900c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2124, -0.3684,  0.0947],\n",
            "        [-0.5132,  0.6207,  0.5512]])\n",
            "cuda\n",
            "tensor([[-0.3171, -2.1175,  0.2624],\n",
            "        [-0.5869,  1.6251, -1.1863]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-02577494bbfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tensor가 같은 위치에 있지 않아서 에러 발생(x2 위치 : gpu(cuda), x3 위치 : cpu)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "metadata": {
        "id": "ddeXFAV5rKlv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## dataset load\n",
        "mnist = fetch_openml('mnist_784')\n",
        "\n",
        "# x_data = mnist.data.astype('float32')\n",
        "x_data = mnist.data\n",
        "y_data = mnist.target.astype(int)"
      ],
      "metadata": {
        "id": "u9dqPk1jr2N_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = \"cpu\"\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "X_train, X_test = torch.tensor(X_train.values, dtype='float32'), torch.tensor(X_test.values, dtype='float32')\n",
        "y_train, y_test = torch.tensor(y_train.values), torch.tensor(y_test.values)\n",
        "X_train = X_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "wcoak-6GsQw_",
        "outputId": "ebae1304-27bb-4e08-b346-7b8dfbd999e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([56000, 784])\n",
            "torch.Size([14000, 784])\n",
            "torch.Size([56000])\n",
            "torch.Size([14000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegression Model\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "  def forward(self, x):\n",
        "    outputs = torch.sigmoid(self.linear(x))\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "eVcZkJHvs94M"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "m = nn.Linear(20,30)\n",
        "input = torch.randn(128,20)\n",
        "output = m(input)\n",
        "print(output.shape)\n",
        "print(m.weight.shape)"
      ],
      "metadata": {
        "id": "hj55jyWEteV_",
        "outputId": "d3d7bc90-9b32-4ec1-a7a6-3d69b93e2a2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 30])\n",
            "torch.Size([30, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hypter parameters\n",
        "epochs = 1000\n",
        "input_dim = 784\n",
        "output_dim = 10\n",
        "lr = 0.01\n",
        "model = LogisticRegression(input_dim, output_dim)\n",
        "model = model.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "LCA_n0S4tvvD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_save_arr=[]\n",
        "for i in range(epochs):\n",
        "  # Train\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  output = model(X_train)\n",
        "  loss = criterion(output, y_train.long())\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  loss_save_arr.append(loss.data)\n",
        "\n",
        "  if (i%100 == 0):\n",
        "    print(\"=====\")\n",
        "    print(\"epoch \", i)\n",
        "    print(\"loss \", loss.data)\n",
        "    _, pred = torch.max(output.data, axis=1)\n",
        "    print(\"train_accuracy : {:0.3f}\".format(float((pred==y_train).sum())/y_train.size(0)))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      output = model(X_test)\n",
        "      _, pred = torch.max(output.data, axis=1)\n",
        "      print(\"train_accuracy : {:0.3f}\".format(float((pred==y_test).sum())/y_test.size(0)))"
      ],
      "metadata": {
        "id": "CtvkjloiuKlu",
        "outputId": "83f6de39-bb40-4747-a80c-278b7784b81e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====\n",
            "epoch  0\n",
            "loss  tensor(2.4483)\n",
            "train_accuracy : 0.141\n",
            "train_accuracy : 0.183\n",
            "=====\n",
            "epoch  100\n",
            "loss  tensor(1.6572)\n",
            "train_accuracy : 0.781\n",
            "train_accuracy : 0.786\n",
            "=====\n",
            "epoch  200\n",
            "loss  tensor(1.6028)\n",
            "train_accuracy : 0.845\n",
            "train_accuracy : 0.848\n",
            "=====\n",
            "epoch  300\n",
            "loss  tensor(1.5883)\n",
            "train_accuracy : 0.861\n",
            "train_accuracy : 0.863\n",
            "=====\n",
            "epoch  400\n",
            "loss  tensor(1.5805)\n",
            "train_accuracy : 0.869\n",
            "train_accuracy : 0.870\n",
            "=====\n",
            "epoch  500\n",
            "loss  tensor(1.5754)\n",
            "train_accuracy : 0.875\n",
            "train_accuracy : 0.876\n",
            "=====\n",
            "epoch  600\n",
            "loss  tensor(1.5712)\n",
            "train_accuracy : 0.880\n",
            "train_accuracy : 0.879\n",
            "=====\n",
            "epoch  700\n",
            "loss  tensor(1.5681)\n",
            "train_accuracy : 0.883\n",
            "train_accuracy : 0.881\n",
            "=====\n",
            "epoch  800\n",
            "loss  tensor(1.5652)\n",
            "train_accuracy : 0.886\n",
            "train_accuracy : 0.883\n",
            "=====\n",
            "epoch  900\n",
            "loss  tensor(1.5631)\n",
            "train_accuracy : 0.888\n",
            "train_accuracy : 0.885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(range(epochs), [e.to(\"cpu\") for e in loss_save_arr])"
      ],
      "metadata": {
        "id": "59BKaj4pvUJR",
        "outputId": "6a177648-9e6d-4f45-ab5e-60a3fd343323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f182c8272d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "pytorch-basics.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}