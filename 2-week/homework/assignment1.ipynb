{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dgf8Q3m07uKT"
      },
      "outputs": [],
      "source": [
        "# Assignment 1\n",
        "# 60191667 유도진\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784')\n",
        "x_data = mnist.data.astype('float32')\n",
        "y_data = mnist.target.astype(int)"
      ],
      "metadata": {
        "id": "b7NHgf33-wOv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "\n",
        "device = \"cuda\"\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "X_train, X_test = torch.tensor(X_train.values), torch.tensor(X_test.values)\n",
        "y_train, y_test = torch.tensor(y_train.values), torch.tensor(y_test.values)\n",
        "X_train = X_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "uu0Z75ci-23j",
        "outputId": "648aca19-9711-4800-ac0f-12a5f5fe01af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([56000, 784])\n",
            "torch.Size([14000, 784])\n",
            "torch.Size([56000])\n",
            "torch.Size([14000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegression Model\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "  def forward(self, x):\n",
        "    outputs = torch.sigmoid(self.linear(x))\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "zqmUgp3Y-3Mi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hypter parameters\n",
        "epochs = 10000\n",
        "input_dim = 784\n",
        "output_dim = 10\n",
        "lr = 0.01\n",
        "model = LogisticRegression(input_dim, output_dim)\n",
        "model = model.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "LSiwe1HR_vuq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_save_arr=[]\n",
        "for i in range(epochs):\n",
        "  # Train\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  output = model(X_train)\n",
        "  loss = criterion(output, y_train.long())\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  loss_save_arr.append(loss.data)\n",
        "\n",
        "  if (i%1000 == 0):\n",
        "    print(\"=====\")\n",
        "    print(\"epoch \", i)\n",
        "    print(\"loss \", loss.data)\n",
        "    _, pred = torch.max(output.data, axis=1)\n",
        "    print(\"train_accuracy : {:0.3f}\".format(float((pred==y_train).sum())/y_train.size(0)))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      output = model(X_test)\n",
        "      _, pred = torch.max(output.data, axis=1)\n",
        "      print(\"test_accuracy : {:0.3f}\".format(float((pred==y_test).sum())/y_test.size(0)))"
      ],
      "metadata": {
        "id": "5IvA1Zyl_0Ep",
        "outputId": "e01f5054-9984-4e31-aed7-0ad71fd7d17f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====\n",
            "epoch  0\n",
            "loss  tensor(2.4327, device='cuda:0')\n",
            "train_accuracy : 0.094\n",
            "test_accuracy : 0.135\n",
            "=====\n",
            "epoch  1000\n",
            "loss  tensor(1.5618, device='cuda:0')\n",
            "train_accuracy : 0.889\n",
            "test_accuracy : 0.889\n",
            "=====\n",
            "epoch  2000\n",
            "loss  tensor(1.5523, device='cuda:0')\n",
            "train_accuracy : 0.898\n",
            "test_accuracy : 0.895\n",
            "=====\n",
            "epoch  3000\n",
            "loss  tensor(1.5480, device='cuda:0')\n",
            "train_accuracy : 0.901\n",
            "test_accuracy : 0.898\n",
            "=====\n",
            "epoch  4000\n",
            "loss  tensor(1.5472, device='cuda:0')\n",
            "train_accuracy : 0.903\n",
            "test_accuracy : 0.899\n",
            "=====\n",
            "epoch  5000\n",
            "loss  tensor(1.5437, device='cuda:0')\n",
            "train_accuracy : 0.904\n",
            "test_accuracy : 0.899\n",
            "=====\n",
            "epoch  6000\n",
            "loss  tensor(1.5432, device='cuda:0')\n",
            "train_accuracy : 0.905\n",
            "test_accuracy : 0.900\n",
            "=====\n",
            "epoch  7000\n",
            "loss  tensor(1.5418, device='cuda:0')\n",
            "train_accuracy : 0.905\n",
            "test_accuracy : 0.902\n",
            "=====\n",
            "epoch  8000\n",
            "loss  tensor(1.5408, device='cuda:0')\n",
            "train_accuracy : 0.906\n",
            "test_accuracy : 0.902\n",
            "=====\n",
            "epoch  9000\n",
            "loss  tensor(1.5397, device='cuda:0')\n",
            "train_accuracy : 0.906\n",
            "test_accuracy : 0.902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q. Accuracy를 올리기 위해서 무엇을 추가할 수 있을 지 한줄로 작성\n",
        "learing rate 값을 여러 가지로 변경하면서 모델을 학습시켜본다. epoch값이 1000일 때와 9000일 때의 정확도의 큰 차이가 없다. 1000 epoch 이전에 minimum을 찾고 그 값으로 수렴했기 때문이다. 따라서 lr을 바꿔가며 다른 minimum이 있는 지 확인하는 과정을 통해서 성능을 개선시켜볼 수 있을 것 같다."
      ],
      "metadata": {
        "id": "h9GNeL1YCH6_"
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "assignment1.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}